{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed7e8d32",
      "metadata": {
        "id": "ed7e8d32"
      },
      "source": [
        "\n",
        "# CNN Model Implementation and Hybrid Model in PyTorch\n",
        "\n",
        "## Overview\n",
        "This notebook covers two tasks:\n",
        "1. Implementation of two well-known CNN architectures from scratch and comparison with PyTorch built-in models.\n",
        "2. Creating a hybrid model combining the best features of the two architectures to achieve better performance.\n",
        "\n",
        "### Task 1: Implementing VGG and ResNet from Scratch\n",
        "- We'll choose two models: **VGG** and **ResNet**.\n",
        "- Implement them from scratch and compare their performance with the built-in versions in PyTorch.\n",
        "\n",
        "### Task 2: Creating a Hybrid Model\n",
        "- Combine features from both VGG and ResNet to create a hybrid model.\n",
        "- Evaluate its performance and see if it outperforms the individual models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56cda2a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56cda2a2",
        "outputId": "e5d27eaa-b4c5-45f6-ac35-b063dd34a6f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:11<00:00, 15.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "VGG_Scratch(\n",
            "  (conv_layers): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU()\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU()\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU()\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU()\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU()\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layers): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "ResNet_Scratch(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "# Device configuration (GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define basic parameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Dataset and DataLoader (using CIFAR-10 as an example)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 1. VGG-like network from scratch\n",
        "class VGG_Scratch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG_Scratch, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 10)  # CIFAR-10 has 10 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the VGG-like model from scratch\n",
        "model_vgg_scratch = VGG_Scratch().to(device)\n",
        "\n",
        "# 2. ResNet-like network from scratch\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet_Scratch(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet_Scratch, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = F.avg_pool2d(x, 4)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize ResNet-like model from scratch\n",
        "model_resnet_scratch = ResNet_Scratch(BasicBlock, [2, 2, 2, 2]).to(device)\n",
        "\n",
        "# Display both model architectures\n",
        "print(model_vgg_scratch)\n",
        "print(model_resnet_scratch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3193c6e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3193c6e4",
        "outputId": "ccfbeff4-e474-49da-ba9e-1b2e2ebd75f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HybridModel(\n",
            "  (vgg_part): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (res_block): BasicBlock(\n",
            "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU()\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=32768, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Hybrid model combining aspects of both VGG and ResNet\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridModel, self).__init__()\n",
        "\n",
        "        # VGG-inspired convolutional layers\n",
        "        self.vgg_part = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # ResNet-inspired residual block\n",
        "        self.res_block = BasicBlock(128, 128)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128 * 16 * 16, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)  # 10 classes for CIFAR-10\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vgg_part(x)\n",
        "        x = self.res_block(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the hybrid model\n",
        "model_hybrid = HybridModel().to(device)\n",
        "\n",
        "# Display the hybrid model architecture\n",
        "print(model_hybrid)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Testing function to calculate accuracy\n",
        "def test(model, test_loader):\n",
        "    model.eval()  # Evaluation mode\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        return accuracy\n",
        "\n",
        "# Loss and optimizer for all models\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 1. Train and test VGG-like model from scratch\n",
        "optimizer_vgg = optim.Adam(model_vgg_scratch.parameters(), lr=learning_rate)\n",
        "print(\"Training VGG-like model from scratch...\")\n",
        "train(model_vgg_scratch, train_loader, criterion, optimizer_vgg, num_epochs)\n",
        "accuracy_vgg_scratch = test(model_vgg_scratch, test_loader)\n",
        "print(f'VGG-like Model from scratch Test Accuracy: {accuracy_vgg_scratch:.2f}%')\n",
        "\n",
        "# 2. Train and test ResNet-like model from scratch\n",
        "optimizer_resnet = optim.Adam(model_resnet_scratch.parameters(), lr=learning_rate)\n",
        "print(\"Training ResNet-like model from scratch...\")\n",
        "train(model_resnet_scratch, train_loader, criterion, optimizer_resnet, num_epochs)\n",
        "accuracy_resnet_scratch = test(model_resnet_scratch, test_loader)\n",
        "print(f'ResNet-like Model from scratch Test Accuracy: {accuracy_resnet_scratch:.2f}%')\n",
        "\n",
        "# 3. Train and test Hybrid model\n",
        "optimizer_hybrid = optim.Adam(model_hybrid.parameters(), lr=learning_rate)\n",
        "print(\"Training Hybrid model...\")\n",
        "train(model_hybrid, train_loader, criterion, optimizer_hybrid, num_epochs)\n",
        "accuracy_hybrid = test(model_hybrid, test_loader)\n",
        "print(f'Hybrid Model Test Accuracy: {accuracy_hybrid:.2f}%')\n",
        "\n",
        "# Compare with PyTorch built-in VGG and ResNet\n",
        "from torchvision import models\n",
        "\n",
        "# 4. PyTorch built-in VGG model (using VGG11)\n",
        "model_vgg_builtin = models.vgg11(pretrained=False, num_classes=10).to(device)\n",
        "optimizer_vgg_builtin = optim.Adam(model_vgg_builtin.parameters(), lr=learning_rate)\n",
        "print(\"Training PyTorch built-in VGG model...\")\n",
        "train(model_vgg_builtin, train_loader, criterion, optimizer_vgg_builtin, num_epochs)\n",
        "accuracy_vgg_builtin = test(model_vgg_builtin, test_loader)\n",
        "print(f'PyTorch built-in VGG Model Test Accuracy: {accuracy_vgg_builtin:.2f}%')\n",
        "\n",
        "# 5. PyTorch built-in ResNet model (using ResNet18)\n",
        "model_resnet_builtin = models.resnet18(pretrained=False, num_classes=10).to(device)\n",
        "optimizer_resnet_builtin = optim.Adam(model_resnet_builtin.parameters(), lr=learning_rate)\n",
        "print(\"Training PyTorch built-in ResNet model...\")\n",
        "train(model_resnet_builtin, train_loader, criterion, optimizer_resnet_builtin, num_epochs)\n",
        "accuracy_resnet_builtin = test(model_resnet_builtin, test_loader)\n",
        "print(f'PyTorch built-in ResNet Model Test Accuracy: {accuracy_resnet_builtin:.2f}%')\n",
        "\n",
        "# Final performance comparison\n",
        "print(f\"VGG-like Model (Scratch) Accuracy: {accuracy_vgg_scratch:.2f}%\")\n",
        "print(f\"ResNet-like Model (Scratch) Accuracy: {accuracy_resnet_scratch:.2f}%\")\n",
        "print(f\"Hybrid Model Accuracy: {accuracy_hybrid:.2f}%\")\n",
        "print(f\"PyTorch Built-in VGG Model Accuracy: {accuracy_vgg_builtin:.2f}%\")\n",
        "print(f\"PyTorch Built-in ResNet Model Accuracy: {accuracy_resnet_builtin:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIZR0T8anxX0",
        "outputId": "3d5e3136-e79f-4d60-9681-df6d17cae9cd"
      },
      "id": "fIZR0T8anxX0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training VGG-like model from scratch...\n",
            "Epoch [1/10], Step [100/782], Loss: 2.2074\n",
            "Epoch [1/10], Step [200/782], Loss: 1.8572\n",
            "Epoch [1/10], Step [300/782], Loss: 1.7206\n",
            "Epoch [1/10], Step [400/782], Loss: 1.7597\n",
            "Epoch [1/10], Step [500/782], Loss: 1.6427\n",
            "Epoch [1/10], Step [600/782], Loss: 1.3949\n",
            "Epoch [1/10], Step [700/782], Loss: 1.3690\n",
            "Epoch [2/10], Step [100/782], Loss: 1.3306\n",
            "Epoch [2/10], Step [200/782], Loss: 1.2617\n",
            "Epoch [2/10], Step [300/782], Loss: 1.0859\n",
            "Epoch [2/10], Step [400/782], Loss: 1.2066\n",
            "Epoch [2/10], Step [500/782], Loss: 1.1758\n",
            "Epoch [2/10], Step [600/782], Loss: 1.3204\n",
            "Epoch [2/10], Step [700/782], Loss: 1.2354\n",
            "Epoch [3/10], Step [100/782], Loss: 1.3279\n",
            "Epoch [3/10], Step [200/782], Loss: 1.0677\n",
            "Epoch [3/10], Step [300/782], Loss: 1.1709\n",
            "Epoch [3/10], Step [400/782], Loss: 1.3054\n",
            "Epoch [3/10], Step [500/782], Loss: 0.9375\n",
            "Epoch [3/10], Step [600/782], Loss: 1.2501\n",
            "Epoch [3/10], Step [700/782], Loss: 1.0430\n",
            "Epoch [4/10], Step [100/782], Loss: 1.1043\n",
            "Epoch [4/10], Step [200/782], Loss: 0.7931\n",
            "Epoch [4/10], Step [300/782], Loss: 0.9938\n",
            "Epoch [4/10], Step [400/782], Loss: 0.9687\n",
            "Epoch [4/10], Step [500/782], Loss: 0.7429\n",
            "Epoch [4/10], Step [600/782], Loss: 0.7867\n",
            "Epoch [4/10], Step [700/782], Loss: 0.6992\n",
            "Epoch [5/10], Step [100/782], Loss: 0.6153\n",
            "Epoch [5/10], Step [200/782], Loss: 0.6897\n",
            "Epoch [5/10], Step [300/782], Loss: 1.0407\n",
            "Epoch [5/10], Step [400/782], Loss: 0.8089\n",
            "Epoch [5/10], Step [500/782], Loss: 0.8753\n",
            "Epoch [5/10], Step [600/782], Loss: 0.7730\n",
            "Epoch [5/10], Step [700/782], Loss: 0.5652\n",
            "Epoch [6/10], Step [100/782], Loss: 0.5919\n",
            "Epoch [6/10], Step [200/782], Loss: 0.8746\n",
            "Epoch [6/10], Step [300/782], Loss: 0.6207\n",
            "Epoch [6/10], Step [400/782], Loss: 0.8620\n",
            "Epoch [6/10], Step [500/782], Loss: 0.4672\n",
            "Epoch [6/10], Step [600/782], Loss: 0.6619\n",
            "Epoch [6/10], Step [700/782], Loss: 0.6615\n",
            "Epoch [7/10], Step [100/782], Loss: 0.7347\n",
            "Epoch [7/10], Step [200/782], Loss: 0.6615\n",
            "Epoch [7/10], Step [300/782], Loss: 0.5725\n",
            "Epoch [7/10], Step [400/782], Loss: 0.5410\n",
            "Epoch [7/10], Step [500/782], Loss: 0.5207\n",
            "Epoch [7/10], Step [600/782], Loss: 0.5266\n",
            "Epoch [7/10], Step [700/782], Loss: 0.9042\n",
            "Epoch [8/10], Step [100/782], Loss: 0.5118\n",
            "Epoch [8/10], Step [200/782], Loss: 0.3886\n",
            "Epoch [8/10], Step [300/782], Loss: 0.7264\n",
            "Epoch [8/10], Step [400/782], Loss: 0.4124\n",
            "Epoch [8/10], Step [500/782], Loss: 0.5706\n",
            "Epoch [8/10], Step [600/782], Loss: 0.6144\n",
            "Epoch [8/10], Step [700/782], Loss: 0.4818\n",
            "Epoch [9/10], Step [100/782], Loss: 0.4112\n",
            "Epoch [9/10], Step [200/782], Loss: 0.6988\n",
            "Epoch [9/10], Step [300/782], Loss: 0.4116\n",
            "Epoch [9/10], Step [400/782], Loss: 0.4125\n",
            "Epoch [9/10], Step [500/782], Loss: 0.5866\n",
            "Epoch [9/10], Step [600/782], Loss: 0.6882\n",
            "Epoch [9/10], Step [700/782], Loss: 0.4362\n",
            "Epoch [10/10], Step [100/782], Loss: 0.5864\n",
            "Epoch [10/10], Step [200/782], Loss: 0.5705\n",
            "Epoch [10/10], Step [300/782], Loss: 0.5231\n",
            "Epoch [10/10], Step [400/782], Loss: 0.3847\n",
            "Epoch [10/10], Step [500/782], Loss: 0.3431\n",
            "Epoch [10/10], Step [600/782], Loss: 0.4306\n",
            "Epoch [10/10], Step [700/782], Loss: 0.3432\n",
            "VGG-like Model from scratch Test Accuracy: 74.27%\n",
            "Training ResNet-like model from scratch...\n",
            "Epoch [1/10], Step [100/782], Loss: 1.6701\n",
            "Epoch [1/10], Step [200/782], Loss: 1.6011\n",
            "Epoch [1/10], Step [300/782], Loss: 1.4447\n",
            "Epoch [1/10], Step [400/782], Loss: 1.2862\n",
            "Epoch [1/10], Step [500/782], Loss: 1.1555\n",
            "Epoch [1/10], Step [600/782], Loss: 1.1751\n",
            "Epoch [1/10], Step [700/782], Loss: 1.1322\n",
            "Epoch [2/10], Step [100/782], Loss: 1.1176\n",
            "Epoch [2/10], Step [200/782], Loss: 0.7475\n",
            "Epoch [2/10], Step [300/782], Loss: 0.8508\n",
            "Epoch [2/10], Step [400/782], Loss: 0.8879\n",
            "Epoch [2/10], Step [500/782], Loss: 0.7426\n",
            "Epoch [2/10], Step [600/782], Loss: 0.9261\n",
            "Epoch [2/10], Step [700/782], Loss: 0.9372\n",
            "Epoch [3/10], Step [100/782], Loss: 0.8973\n",
            "Epoch [3/10], Step [200/782], Loss: 0.6947\n",
            "Epoch [3/10], Step [300/782], Loss: 0.5480\n",
            "Epoch [3/10], Step [400/782], Loss: 0.7176\n",
            "Epoch [3/10], Step [500/782], Loss: 0.8794\n",
            "Epoch [3/10], Step [600/782], Loss: 0.7640\n",
            "Epoch [3/10], Step [700/782], Loss: 0.4586\n",
            "Epoch [4/10], Step [100/782], Loss: 0.2530\n",
            "Epoch [4/10], Step [200/782], Loss: 0.6001\n",
            "Epoch [4/10], Step [300/782], Loss: 0.4174\n",
            "Epoch [4/10], Step [400/782], Loss: 0.6417\n",
            "Epoch [4/10], Step [500/782], Loss: 0.3591\n",
            "Epoch [4/10], Step [600/782], Loss: 0.6183\n",
            "Epoch [4/10], Step [700/782], Loss: 0.4001\n",
            "Epoch [5/10], Step [100/782], Loss: 0.3620\n",
            "Epoch [5/10], Step [200/782], Loss: 0.4092\n",
            "Epoch [5/10], Step [300/782], Loss: 0.6341\n",
            "Epoch [5/10], Step [400/782], Loss: 0.3587\n",
            "Epoch [5/10], Step [500/782], Loss: 0.2335\n",
            "Epoch [5/10], Step [600/782], Loss: 0.3830\n",
            "Epoch [5/10], Step [700/782], Loss: 0.3587\n",
            "Epoch [6/10], Step [100/782], Loss: 0.1570\n",
            "Epoch [6/10], Step [200/782], Loss: 0.3513\n",
            "Epoch [6/10], Step [300/782], Loss: 0.1355\n",
            "Epoch [6/10], Step [400/782], Loss: 0.1369\n",
            "Epoch [6/10], Step [500/782], Loss: 0.3366\n",
            "Epoch [6/10], Step [600/782], Loss: 0.2784\n",
            "Epoch [6/10], Step [700/782], Loss: 0.3048\n",
            "Epoch [7/10], Step [100/782], Loss: 0.1622\n",
            "Epoch [7/10], Step [200/782], Loss: 0.1075\n",
            "Epoch [7/10], Step [300/782], Loss: 0.1604\n",
            "Epoch [7/10], Step [400/782], Loss: 0.2084\n",
            "Epoch [7/10], Step [500/782], Loss: 0.1967\n",
            "Epoch [7/10], Step [600/782], Loss: 0.1450\n",
            "Epoch [7/10], Step [700/782], Loss: 0.1743\n",
            "Epoch [8/10], Step [100/782], Loss: 0.0809\n",
            "Epoch [8/10], Step [200/782], Loss: 0.2223\n",
            "Epoch [8/10], Step [300/782], Loss: 0.2385\n",
            "Epoch [8/10], Step [400/782], Loss: 0.2129\n",
            "Epoch [8/10], Step [500/782], Loss: 0.0958\n",
            "Epoch [8/10], Step [600/782], Loss: 0.2387\n",
            "Epoch [8/10], Step [700/782], Loss: 0.4471\n",
            "Epoch [9/10], Step [100/782], Loss: 0.0511\n",
            "Epoch [9/10], Step [200/782], Loss: 0.1421\n",
            "Epoch [9/10], Step [300/782], Loss: 0.1324\n",
            "Epoch [9/10], Step [400/782], Loss: 0.1263\n",
            "Epoch [9/10], Step [500/782], Loss: 0.1243\n",
            "Epoch [9/10], Step [600/782], Loss: 0.0695\n",
            "Epoch [9/10], Step [700/782], Loss: 0.1388\n",
            "Epoch [10/10], Step [100/782], Loss: 0.1101\n",
            "Epoch [10/10], Step [200/782], Loss: 0.0961\n",
            "Epoch [10/10], Step [300/782], Loss: 0.0205\n",
            "Epoch [10/10], Step [400/782], Loss: 0.0877\n",
            "Epoch [10/10], Step [500/782], Loss: 0.0720\n",
            "Epoch [10/10], Step [600/782], Loss: 0.0544\n",
            "Epoch [10/10], Step [700/782], Loss: 0.1306\n",
            "ResNet-like Model from scratch Test Accuracy: 83.49%\n",
            "Training Hybrid model...\n",
            "Epoch [1/10], Step [100/782], Loss: 1.6543\n",
            "Epoch [1/10], Step [200/782], Loss: 1.1317\n",
            "Epoch [1/10], Step [300/782], Loss: 1.0260\n",
            "Epoch [1/10], Step [400/782], Loss: 1.1325\n",
            "Epoch [1/10], Step [500/782], Loss: 1.1833\n",
            "Epoch [1/10], Step [600/782], Loss: 1.2709\n",
            "Epoch [1/10], Step [700/782], Loss: 0.8440\n",
            "Epoch [2/10], Step [100/782], Loss: 0.8128\n",
            "Epoch [2/10], Step [200/782], Loss: 0.7947\n",
            "Epoch [2/10], Step [300/782], Loss: 1.2056\n",
            "Epoch [2/10], Step [400/782], Loss: 0.6259\n",
            "Epoch [2/10], Step [500/782], Loss: 0.7187\n",
            "Epoch [2/10], Step [600/782], Loss: 0.8407\n",
            "Epoch [2/10], Step [700/782], Loss: 1.0444\n",
            "Epoch [3/10], Step [100/782], Loss: 0.7616\n",
            "Epoch [3/10], Step [200/782], Loss: 0.8573\n",
            "Epoch [3/10], Step [300/782], Loss: 0.6202\n",
            "Epoch [3/10], Step [400/782], Loss: 0.5812\n",
            "Epoch [3/10], Step [500/782], Loss: 0.7857\n",
            "Epoch [3/10], Step [600/782], Loss: 0.5490\n",
            "Epoch [3/10], Step [700/782], Loss: 0.4724\n",
            "Epoch [4/10], Step [100/782], Loss: 0.5026\n",
            "Epoch [4/10], Step [200/782], Loss: 0.3154\n",
            "Epoch [4/10], Step [300/782], Loss: 0.7549\n",
            "Epoch [4/10], Step [400/782], Loss: 0.6604\n",
            "Epoch [4/10], Step [500/782], Loss: 0.4073\n",
            "Epoch [4/10], Step [600/782], Loss: 0.5617\n",
            "Epoch [4/10], Step [700/782], Loss: 0.6298\n",
            "Epoch [5/10], Step [100/782], Loss: 0.7004\n",
            "Epoch [5/10], Step [200/782], Loss: 0.3777\n",
            "Epoch [5/10], Step [300/782], Loss: 0.3694\n",
            "Epoch [5/10], Step [400/782], Loss: 0.3855\n",
            "Epoch [5/10], Step [500/782], Loss: 0.3608\n",
            "Epoch [5/10], Step [600/782], Loss: 0.4587\n",
            "Epoch [5/10], Step [700/782], Loss: 0.6330\n",
            "Epoch [6/10], Step [100/782], Loss: 0.3906\n",
            "Epoch [6/10], Step [200/782], Loss: 0.3157\n",
            "Epoch [6/10], Step [300/782], Loss: 0.4554\n",
            "Epoch [6/10], Step [400/782], Loss: 0.3858\n",
            "Epoch [6/10], Step [500/782], Loss: 0.5278\n",
            "Epoch [6/10], Step [600/782], Loss: 0.3334\n",
            "Epoch [6/10], Step [700/782], Loss: 0.4445\n",
            "Epoch [7/10], Step [100/782], Loss: 0.3182\n",
            "Epoch [7/10], Step [200/782], Loss: 0.3070\n",
            "Epoch [7/10], Step [300/782], Loss: 0.2140\n",
            "Epoch [7/10], Step [400/782], Loss: 0.2425\n",
            "Epoch [7/10], Step [500/782], Loss: 0.2693\n",
            "Epoch [7/10], Step [600/782], Loss: 0.5024\n",
            "Epoch [7/10], Step [700/782], Loss: 0.2162\n",
            "Epoch [8/10], Step [100/782], Loss: 0.0965\n",
            "Epoch [8/10], Step [200/782], Loss: 0.1089\n",
            "Epoch [8/10], Step [300/782], Loss: 0.2026\n",
            "Epoch [8/10], Step [400/782], Loss: 0.2680\n",
            "Epoch [8/10], Step [500/782], Loss: 0.2568\n",
            "Epoch [8/10], Step [600/782], Loss: 0.3938\n",
            "Epoch [8/10], Step [700/782], Loss: 0.2768\n",
            "Epoch [9/10], Step [100/782], Loss: 0.1866\n",
            "Epoch [9/10], Step [200/782], Loss: 0.1917\n",
            "Epoch [9/10], Step [300/782], Loss: 0.1116\n",
            "Epoch [9/10], Step [400/782], Loss: 0.2106\n",
            "Epoch [9/10], Step [500/782], Loss: 0.1668\n",
            "Epoch [9/10], Step [600/782], Loss: 0.2464\n",
            "Epoch [9/10], Step [700/782], Loss: 0.2083\n",
            "Epoch [10/10], Step [100/782], Loss: 0.0848\n",
            "Epoch [10/10], Step [200/782], Loss: 0.1546\n",
            "Epoch [10/10], Step [300/782], Loss: 0.0563\n",
            "Epoch [10/10], Step [400/782], Loss: 0.0954\n",
            "Epoch [10/10], Step [500/782], Loss: 0.3228\n",
            "Epoch [10/10], Step [600/782], Loss: 0.1653\n",
            "Epoch [10/10], Step [700/782], Loss: 0.1875\n",
            "Hybrid Model Test Accuracy: 78.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PyTorch built-in VGG model...\n",
            "Epoch [1/10], Step [100/782], Loss: 2.2824\n",
            "Epoch [1/10], Step [200/782], Loss: 1.9505\n",
            "Epoch [1/10], Step [300/782], Loss: 1.8361\n",
            "Epoch [1/10], Step [400/782], Loss: 1.8652\n",
            "Epoch [1/10], Step [500/782], Loss: 1.6995\n",
            "Epoch [1/10], Step [600/782], Loss: 1.6538\n",
            "Epoch [1/10], Step [700/782], Loss: 1.4796\n",
            "Epoch [2/10], Step [100/782], Loss: 1.6612\n",
            "Epoch [2/10], Step [200/782], Loss: 1.1077\n",
            "Epoch [2/10], Step [300/782], Loss: 1.3389\n",
            "Epoch [2/10], Step [400/782], Loss: 1.7847\n",
            "Epoch [2/10], Step [500/782], Loss: 1.2431\n",
            "Epoch [2/10], Step [600/782], Loss: 1.0621\n",
            "Epoch [2/10], Step [700/782], Loss: 1.2789\n",
            "Epoch [3/10], Step [100/782], Loss: 1.1831\n",
            "Epoch [3/10], Step [200/782], Loss: 1.1176\n",
            "Epoch [3/10], Step [300/782], Loss: 1.1273\n",
            "Epoch [3/10], Step [400/782], Loss: 0.9448\n",
            "Epoch [3/10], Step [500/782], Loss: 1.2227\n",
            "Epoch [3/10], Step [600/782], Loss: 0.9243\n",
            "Epoch [3/10], Step [700/782], Loss: 0.8321\n",
            "Epoch [4/10], Step [100/782], Loss: 0.9763\n",
            "Epoch [4/10], Step [200/782], Loss: 0.7019\n",
            "Epoch [4/10], Step [300/782], Loss: 1.0446\n",
            "Epoch [4/10], Step [400/782], Loss: 0.8068\n",
            "Epoch [4/10], Step [500/782], Loss: 0.9526\n",
            "Epoch [4/10], Step [600/782], Loss: 0.8835\n",
            "Epoch [4/10], Step [700/782], Loss: 0.8805\n",
            "Epoch [5/10], Step [100/782], Loss: 0.9396\n",
            "Epoch [5/10], Step [200/782], Loss: 0.7800\n",
            "Epoch [5/10], Step [300/782], Loss: 0.6185\n",
            "Epoch [5/10], Step [400/782], Loss: 0.8344\n",
            "Epoch [5/10], Step [500/782], Loss: 0.9029\n",
            "Epoch [5/10], Step [600/782], Loss: 0.7671\n",
            "Epoch [5/10], Step [700/782], Loss: 0.7430\n",
            "Epoch [6/10], Step [100/782], Loss: 1.0320\n",
            "Epoch [6/10], Step [200/782], Loss: 0.7356\n",
            "Epoch [6/10], Step [300/782], Loss: 0.8656\n",
            "Epoch [6/10], Step [400/782], Loss: 0.8552\n",
            "Epoch [6/10], Step [500/782], Loss: 0.6292\n",
            "Epoch [6/10], Step [600/782], Loss: 0.9227\n",
            "Epoch [6/10], Step [700/782], Loss: 0.6016\n",
            "Epoch [7/10], Step [100/782], Loss: 0.6346\n",
            "Epoch [7/10], Step [200/782], Loss: 0.7255\n",
            "Epoch [7/10], Step [300/782], Loss: 0.9061\n",
            "Epoch [7/10], Step [400/782], Loss: 0.9685\n",
            "Epoch [7/10], Step [500/782], Loss: 0.7240\n",
            "Epoch [7/10], Step [600/782], Loss: 0.7123\n",
            "Epoch [7/10], Step [700/782], Loss: 0.8660\n",
            "Epoch [8/10], Step [100/782], Loss: 0.6971\n",
            "Epoch [8/10], Step [200/782], Loss: 0.6143\n",
            "Epoch [8/10], Step [300/782], Loss: 0.9277\n",
            "Epoch [8/10], Step [400/782], Loss: 0.7294\n",
            "Epoch [8/10], Step [500/782], Loss: 0.5366\n",
            "Epoch [8/10], Step [600/782], Loss: 0.8082\n",
            "Epoch [8/10], Step [700/782], Loss: 0.5015\n",
            "Epoch [9/10], Step [100/782], Loss: 0.5420\n",
            "Epoch [9/10], Step [200/782], Loss: 0.5950\n",
            "Epoch [9/10], Step [300/782], Loss: 0.4835\n",
            "Epoch [9/10], Step [400/782], Loss: 0.3879\n",
            "Epoch [9/10], Step [500/782], Loss: 0.5742\n",
            "Epoch [9/10], Step [600/782], Loss: 0.5955\n",
            "Epoch [9/10], Step [700/782], Loss: 0.5037\n",
            "Epoch [10/10], Step [100/782], Loss: 0.4472\n",
            "Epoch [10/10], Step [200/782], Loss: 0.8654\n",
            "Epoch [10/10], Step [300/782], Loss: 0.6806\n",
            "Epoch [10/10], Step [400/782], Loss: 0.5975\n",
            "Epoch [10/10], Step [500/782], Loss: 0.6100\n",
            "Epoch [10/10], Step [600/782], Loss: 0.6713\n",
            "Epoch [10/10], Step [700/782], Loss: 0.5237\n",
            "PyTorch built-in VGG Model Test Accuracy: 72.01%\n",
            "Training PyTorch built-in ResNet model...\n",
            "Epoch [1/10], Step [100/782], Loss: 1.5985\n",
            "Epoch [1/10], Step [200/782], Loss: 1.3243\n",
            "Epoch [1/10], Step [300/782], Loss: 1.2336\n",
            "Epoch [1/10], Step [400/782], Loss: 1.2408\n",
            "Epoch [1/10], Step [500/782], Loss: 1.2846\n",
            "Epoch [1/10], Step [600/782], Loss: 0.9659\n",
            "Epoch [1/10], Step [700/782], Loss: 0.9801\n",
            "Epoch [2/10], Step [100/782], Loss: 0.8999\n",
            "Epoch [2/10], Step [200/782], Loss: 0.8498\n",
            "Epoch [2/10], Step [300/782], Loss: 0.9447\n",
            "Epoch [2/10], Step [400/782], Loss: 0.7785\n",
            "Epoch [2/10], Step [500/782], Loss: 0.9888\n",
            "Epoch [2/10], Step [600/782], Loss: 1.0552\n",
            "Epoch [2/10], Step [700/782], Loss: 1.0879\n",
            "Epoch [3/10], Step [100/782], Loss: 0.9381\n",
            "Epoch [3/10], Step [200/782], Loss: 0.7853\n",
            "Epoch [3/10], Step [300/782], Loss: 0.9755\n",
            "Epoch [3/10], Step [400/782], Loss: 0.7588\n",
            "Epoch [3/10], Step [500/782], Loss: 0.8766\n",
            "Epoch [3/10], Step [600/782], Loss: 0.8801\n",
            "Epoch [3/10], Step [700/782], Loss: 0.6601\n",
            "Epoch [4/10], Step [100/782], Loss: 0.4701\n",
            "Epoch [4/10], Step [200/782], Loss: 0.8249\n",
            "Epoch [4/10], Step [300/782], Loss: 0.6258\n",
            "Epoch [4/10], Step [400/782], Loss: 0.7063\n",
            "Epoch [4/10], Step [500/782], Loss: 0.5956\n",
            "Epoch [4/10], Step [600/782], Loss: 0.9103\n",
            "Epoch [4/10], Step [700/782], Loss: 0.7966\n",
            "Epoch [5/10], Step [100/782], Loss: 0.7066\n",
            "Epoch [5/10], Step [200/782], Loss: 0.6601\n",
            "Epoch [5/10], Step [300/782], Loss: 0.4872\n",
            "Epoch [5/10], Step [400/782], Loss: 0.6399\n",
            "Epoch [5/10], Step [500/782], Loss: 0.5525\n",
            "Epoch [5/10], Step [600/782], Loss: 0.5162\n",
            "Epoch [5/10], Step [700/782], Loss: 0.6491\n",
            "Epoch [6/10], Step [100/782], Loss: 0.4734\n",
            "Epoch [6/10], Step [200/782], Loss: 0.6105\n",
            "Epoch [6/10], Step [300/782], Loss: 0.5187\n",
            "Epoch [6/10], Step [400/782], Loss: 0.5468\n",
            "Epoch [6/10], Step [500/782], Loss: 0.4678\n",
            "Epoch [6/10], Step [600/782], Loss: 0.3297\n",
            "Epoch [6/10], Step [700/782], Loss: 0.5069\n",
            "Epoch [7/10], Step [100/782], Loss: 0.2324\n",
            "Epoch [7/10], Step [200/782], Loss: 0.4292\n",
            "Epoch [7/10], Step [300/782], Loss: 0.2302\n",
            "Epoch [7/10], Step [400/782], Loss: 0.2835\n",
            "Epoch [7/10], Step [500/782], Loss: 0.4509\n",
            "Epoch [7/10], Step [600/782], Loss: 0.2943\n",
            "Epoch [7/10], Step [700/782], Loss: 0.4522\n",
            "Epoch [8/10], Step [100/782], Loss: 0.3533\n",
            "Epoch [8/10], Step [200/782], Loss: 0.3237\n",
            "Epoch [8/10], Step [300/782], Loss: 0.3994\n",
            "Epoch [8/10], Step [400/782], Loss: 0.3347\n",
            "Epoch [8/10], Step [500/782], Loss: 0.2776\n",
            "Epoch [8/10], Step [600/782], Loss: 0.3423\n",
            "Epoch [8/10], Step [700/782], Loss: 0.1849\n",
            "Epoch [9/10], Step [100/782], Loss: 0.2598\n",
            "Epoch [9/10], Step [200/782], Loss: 0.4075\n",
            "Epoch [9/10], Step [300/782], Loss: 0.1584\n",
            "Epoch [9/10], Step [400/782], Loss: 0.1220\n",
            "Epoch [9/10], Step [500/782], Loss: 0.2614\n",
            "Epoch [9/10], Step [600/782], Loss: 0.2005\n",
            "Epoch [9/10], Step [700/782], Loss: 0.2070\n",
            "Epoch [10/10], Step [100/782], Loss: 0.2369\n",
            "Epoch [10/10], Step [200/782], Loss: 0.1546\n",
            "Epoch [10/10], Step [300/782], Loss: 0.1460\n",
            "Epoch [10/10], Step [400/782], Loss: 0.1207\n",
            "Epoch [10/10], Step [500/782], Loss: 0.3108\n",
            "Epoch [10/10], Step [600/782], Loss: 0.0791\n",
            "Epoch [10/10], Step [700/782], Loss: 0.2221\n",
            "PyTorch built-in ResNet Model Test Accuracy: 76.92%\n",
            "VGG-like Model (Scratch) Accuracy: 74.27%\n",
            "ResNet-like Model (Scratch) Accuracy: 83.49%\n",
            "Hybrid Model Accuracy: 78.44%\n",
            "PyTorch Built-in VGG Model Accuracy: 72.01%\n",
            "PyTorch Built-in ResNet Model Accuracy: 76.92%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}